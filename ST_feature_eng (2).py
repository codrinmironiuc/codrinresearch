# -*- coding: utf-8 -*-
"""
Research Workshop Feature Engineering

#1. subject - subject number (domain: 1-31)

#2. variant - variant label (domain: 1-3): 
	1 = gentle, 
	2 = normal,
	3 = rough

#3. gesture - gesture label (domain: 1-14): 
	1 = grab, 
	2 = hit, 
	3 = massage, 
	4 = pat, 
	5 = pinch, 
	6 = poke, 
	7 = press, 
	8 = rub, 
	9 = scratch, 
	10 = slap, 
	11 = squeeze, 
	12 = stroke, 
	13 = tap,
	14 = tickle
"""

#Import
import pandas as pd
import numpy as np
import random as rd
import matplotlib.pyplot as plt
import imageio
import os
import glob
from scipy.signal import find_peaks
import matplotlib.lines as lines

#File path

path1 = 'C:/Users/'
path2 = '/OneDrive/Documents/CSAI 2_2/Research Workshop/'
user = ('Gebruiker','daanf')
path = path1 + user[1] + path2


#Data wrangling functions

def split_by_gesture(dataset):
    """Takes full dataset, outputs list with separate gesture dataframes"""
    gest_list = []
    for gesture in range(1,15):
        gest = dataset.loc[dataset[' gesture'] == gesture]
        gest_list.append(gest)
    return gest_list


def seperate_observations(gesture_df):
    """Separates observations based on start and end frame, outputs list of observations"""
    
    obs_list = []
    start_idx = 0
    end_idx = 1

    for i in range(len(gesture_df)):
        
        
        try:
            #Locate next frame
            next_frame = gesture_df.iloc[i+1].loc[' frame'] #raises IndexError when out of bounds
    
            #Check if observation ends
            if next_frame == 1:
                
                #Create empty dataframe
                single_obs = pd.DataFrame(columns = gesture_df.columns)
        
                #Append single observation to empty dataframe
                end_idx = i
                single_obs = gesture_df.iloc[start_idx:end_idx+1]
                start_idx = i+1  
                
                obs_list.append(single_obs) #Append df to list
                  
        except IndexError: #When at the last index of dataset
        
            #Create empty dataframe
            single_obs = pd.DataFrame(columns = gesture_df.columns)
            
            end_idx = len(gesture_df-1) #get last frame
            single_obs = gesture_df.iloc[start_idx:end_idx+1]
            
            obs_list.append(single_obs) #Append df to list
            print("Last frame reached\n")
            
    return obs_list    

def take_sample(dataset, n):
    total_sample = []
    gest_list = split_by_gesture(dataset)
    
    for ges in gest_list:
        obs_list = seperate_observations(ges)
        obs_sample = rd.sample(obs_list, n)
        total_sample.append(obs_sample)
        
    return total_sample
        

#Feature engineering functions
 
def trim_to_frames(observation):
    """Returns trimmed dataframe only containting the frame data"""
    frames = observation[observation.columns[4:]]
    return frames
    
def frame_means(frames):
    """
    Calculate mean channel activation (MFA) for each t
    
    Args:
        frames (pandas.core.frame.DataFrame).
        dataframe generated by the trim_to_frames function

    Returns:
        frame_means (pandas.core.series.Series).
        mean over time
    """
    
    frame_means_lst = frames.apply(np.sum, axis=1)
    return frame_means_lst/64

def channel_means(frames):
    """
    Calculate mean channel activation (MFA) for each channel over time
    
    Args:
        frames (pandas.core.frame.DataFrame).
        dataframe generated by the trim_to_frames function

    Returns:
        frame_means (pandas.core.series.Series).
        mean across channels
    """
    
    #Aplies inner function to all frames
    channel_means_lst = frames.apply(np.sum, axis=0)
    return channel_means_lst/len(frames)

def f1_dur(frames):
    """Gesture Duration"""
    
    return(len(frames))

def f2_gm(frame_means_lst):
    """Grand Mean
    input list from frame_means function"""
    return round(frame_means_lst.mean(), 2)

def f3_sd(frame_means_lst):
    """Standard deviation of mean activation across all channels for each time frame"""
    return round(frame_means_lst.std(), 2)

def f4_ha(frames):
    """return the highest activation frame value of the observation"""
    return frames.max().max()

def f5_pa(frames, threshold = .5):
    """Percentage of channels activated above a certain threshold 
    of the maximum observed activation for that gesture"""
    
    tot_points = f1_dur(frames) * 64
    max_act = f4_ha(frames)
    
    tot_activated = 0
    
    for row, series in frames.iterrows():
        for value in series:
            if value >= max_act * threshold:
                tot_activated += 1
            
    perc_active = round(tot_activated/tot_points, 3)
    
    return perc_active

def f6_np(frame_means_lst):
    """Number of peaks (and troughs) of the frame means graph"""
    
    np_means = frame_means_lst.to_numpy()
        
    peaks, _ = find_peaks(np_means, prominence=10)
    #troughs, _ = find_peaks(-np_means, prominence=10)
    
    return len(peaks) #, len(troughs)

def f7_14_ppr(channel_means_lst):
    """Mean pressure per row across time"""
    start = 0
    end = 8
    
    row_pressures = []
    
    #segmentation of mean calculation by row
    while start != 64:
        cur_row = channel_means_lst[start:end]
        cur_row = round(cur_row, 2)
        
        row_pressures.append( round(np.mean(cur_row), 2) )
        
        start += 8
        end += 8
    
    row_pressures.reverse() #reverse so top row will have index 0 and bottom row index 7
    return row_pressures
        
    
def f15_22_ppc(channel_means_lst):
    """Mean pressure per collumn across time"""
    idx_lst = np.array([56,48,40,32,24,16,8,0])
    cml_np = np.array(channel_means_lst)
    
    col_pressures = []
    
    #segmentation of mean calculation by collumn
    for i in range(8):
        cur_col = list(cml_np[idx_lst])
        
        col_pressures.append( round(np.mean(cur_col), 2) )
        
        idx_lst +=1
        
    return col_pressures

def extract_features(path, filename, save=True, save_name='features.csv'):
    "MAIN FUNCTION"
    features = []
    
    print("Loading file...\n")
    data = pd.read_csv(path + '/' + filename)
    
    print("Seperating observations...")
    gestures = seperate_observations(data)
    
    print("Extracting Features... \nThis might take quite some time.\n")
    
    counter = 0
    no_obs = len(gestures)
    
    for observation in gestures:
        
        counter += 1
        
        if counter % 10 == 0:
            print("{}/{}".format(counter, no_obs))
        
        #Executing preliminary functions
        frames = trim_to_frames(observation)
        fr_mn = frame_means(frames)
        ch_mn = channel_means(frames)
        
        #Constructing label
        label = int( str(observation.iloc[0].loc[' gesture']) + str(observation.iloc[0].loc[' variant']) )
        
        #Feature extraction
        f1 = f1_dur(frames)
        f2 = f2_gm(fr_mn)
        f3 = f3_sd(fr_mn)
        f4 = f4_ha(frames)
        f5 = f5_pa(frames)
        f6 = f6_np(fr_mn)
        f7_14 = f7_14_ppr(ch_mn)
        f15_22 = f15_22_ppc(ch_mn)
        
        #Creating list of extracted features
        obs_features = []
        obs_features.extend([label,f1,f2,f3,f4,f5,f6])
        obs_features.extend(f7_14)
        obs_features.extend(f15_22)
        
        #Add final list to nested feature array
        features.append(obs_features)
    
    print("Feature extraction complete/n")
    
    print("Constructing Dataframe.../n")
    
    columns = ['label', 'duration', 'grand_mean', 'standard deviation', 'max_pressure', 'percentage_active', 'no_peaks',
               'row_1', 'row_2', 'row_3', 'row_4', 'row_5', 'row_6', 'row_7', 'row_8',
               'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8',
               ]
    
    feature_df = pd.DataFrame(features, columns = columns)
    
    
    if save is True:   
        print("Saving {} to: {}".format(save_name, path))
        feature_df.to_csv(path+save_name, index=False)
    
    print("\nCOMPLETE")
    return feature_df




#%% Loading small sample from csv for feature extraction

s_file = 'CoST.csv'
s_dataset = pd.read_csv(path+s_file)

data = seperate_observations(s_dataset)

#%% Main Function

feats = extract_features(path, 'CoST.csv' )
    

#%% Visualizing channel activation


#Select observation by index
obs_no = 17 #select observation by index
obs = data[obs_no]

#Print observation type

gest_type = obs.iloc[0].loc[' gesture'] 
variant_type = obs.iloc[0].loc[' variant']
print(str(gest_type) + '|' + str(variant_type))

#Generating mean pressure graph across all channels by frame
frames = trim_to_frames(obs)
obs_means_act = frame_means(frames)
obs_means_act.plot()


#specifiying path for gif creation
im_path = path + 'plot/'

#Removing exiting png files in the folder
files = glob.glob(im_path + '*.png')
for f in files:
    os.remove(f)


###Reshaping rows to resemble pressure grid and saving each frame as .png 

#Dropping any data except for channel activation
frame = obs.drop(columns=['subject', ' variant', ' gesture', ' frame']) 

#Creating and saving 40 frames of no activation as a start reference
start_f = np.zeros((8,8))

for i in range(40): 
    plt.imsave(im_path + 'a_start' + str(i) + '.png', start_f)                      #To Do: .format this


for index, row in frame.iterrows():
    f_sq = np.array(row).reshape((8,8))
    f_sq = np.flip(f_sq, 0)
    plt.imsave(im_path + 'plot_im' + str(index) + '.png', f_sq, cmap='viridis')     #To Do: .format this

    
###Creating .gif file from .png files
#Source: https://stackoverflow.com/questions/41228209/making-gif-from-images-using-imageio-in-python

png_dir = im_path
images = []
for file_name in os.listdir(png_dir):
    if file_name.endswith('.png'):
        file_path = os.path.join(png_dir, file_name)
        images.append(imageio.imread(file_path))
imageio.mimsave(im_path + 'gesture.gif', images, fps = 135)   


#%%Extra--------------
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#Visualisation of peaks and troughs of a list of observations

def visualize_peaks(data):
    
    idx = -1
    
    for obs in data:
        
        idx += 1
        
        frames = trim_to_frames(obs)
        mean_list = frame_means(frames)
        x = mean_list.to_numpy()
        
        peaks, _ = find_peaks(x, prominence=10) #width=0.005*len(x)
        troughs, _ = find_peaks(-x, prominence=10) #width=0.005*len(x)
        plt.plot(x)
        plt.title("Observation Index {}".format(idx))
        plt.plot(peaks, x[peaks], 'x')
        #plt.plot(troughs, x[troughs], '+', color = 'red')
        plt.plot(np.zeros_like(x), "--", color="gray")
        plt.show()
        
        print( "Observation: {}".format(idx) )
        print( "number of peaks: {}".format(len(peaks)) )
        print( "number of troughs: {}".format(len(troughs)) )
        print("------------------------------")
        
#visualize_peaks(data)
        
#%% Getting a small sample and saving dataframe to new csv file
data = pd.read_csv(path+'CoST.csv')
sample = take_sample(data, 8)

#Transforming loose observations back into a single dataframe
conc_sample = []
for obs in sample:
    conc_obs = pd.concat(obs)
    conc_sample.append(conc_obs)
conc_sample = pd.concat(conc_sample)

#Saving to csv for later use
conc_sample.to_csv(path+'smpl.csv', index=False) 

#%%Loading dataset and splitting observations
file = 'CoST.csv'
dataset = pd.read_csv(path+file)
gestures = split_by_gesture(dataset)
grabs = seperate_observations(gestures[1])

#%%

def visualize_peaks2(data):
    
    idx = -1
    
    for obs in data:
        
        idx += 1
        
        frames = trim_to_frames(obs)
        mean_list = frame_means(frames)
        x = mean_list.to_numpy()
        
        peaks, _ = find_peaks(x, prominence=10) #width=0.005*len(x)
        troughs, _ = find_peaks(-x, prominence=10) #width=0.005*len(x)

        
        plt.plot(x)
        plt.title("Visualisation of a Mean Pressure Across Channels:\nMassage With Medium Intensity")
        plt.plot(peaks, x[peaks], 'x')
        #plt.plot(troughs, x[troughs], '+', color = 'red')
        plt.xlabel("Frame Number")
        plt.ylabel("Mean Pressure")
        plt.axhline(y=194.2, color='blue')
        plt.axhline(y=194.2 + 78.61, color='cyan', linestyle='--')
        plt.axhline(y=194.2 - 78.61, color='cyan', linestyle='--')
        plt.show()
        
        print( "Observation: {}".format(idx) )
        print( "number of peaks: {}".format(len(peaks)) )
        print( "number of troughs: {}".format(len(troughs)) )
        print("------------------------------")
        

obs = data[17:18]
obs_df = data[17]
visualize_peaks2(obs)

#%%
#Saving to csv for later use
obs_df.to_csv(path+'obs17.csv', index=False) 

feats17 = extract_features(path, 'obs17.csv' )